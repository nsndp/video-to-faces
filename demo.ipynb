{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Note: using a GPU runtime is recommended, though CPU is also workable, you'll just have to wait more (10-30 min).*"
      ],
      "metadata": {
        "id": "SCtDf0XVptbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As per the usual Colab routine, start with clicking \"Copy to Drive\" button above.\n",
        "\n",
        "Then execute the following cell to get the sources and do a typical editable Python install.\n",
        "\n",
        "<font size=\"2\">--no-build-isolation flag might be necessary due to https://stackoverflow.com/a/70805903.</font>"
      ],
      "metadata": {
        "id": "51wYoFrB4Q4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone 'https://github.com/nsndp/video-to-faces.git'\n",
        "!pip install --no-build-isolation -e video-to-faces"
      ],
      "metadata": {
        "id": "guFDQqE64QTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you should RESTART THE KERNEL (Runtime -> Restart session), or \"import from ...\" won't work.\n",
        "\n",
        "After restarting, you can run the cell below and confirm the installation by seeing '/content/video-to-faces/src' among the outputs."
      ],
      "metadata": {
        "id": "6pvUoUb4xR2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path"
      ],
      "metadata": {
        "id": "BnJYUT9TxqRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For testing, we're gonna download some YouTube videos using [youtube-dl](https://github.com/ytdl-org/youtube-dl) library.\n",
        "\n",
        "<font size=\"2\">Installing like this instead of just \"pip install youtube-dl\" due to https://stackoverflow.com/a/75504772.</font>\n",
        "\n",
        "<font size=\"2\">-f 22 corresponds to a 720p mp4 version of a video (all formats can be listed with \"yt-dlp -F \\<url\\>\").</font>"
      ],
      "metadata": {
        "id": "rFoTUHV07_2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz"
      ],
      "metadata": {
        "id": "j0ao4l5Y8IOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir videos\n",
        "!yt-dlp -o videos/DrHorribleAct1.mp4 -f 22 https://www.youtube.com/watch?v=MPImhprnUsE\n",
        "!yt-dlp -o videos/Railgun1FanTrailer.mp4 -f 22 https://www.youtube.com/watch?v=jL_vEw6hObw\n",
        "!yt-dlp -o videos/LycoRecoTrailer.mp4 -f 22 https://www.youtube.com/watch?v=F5DMjhg3A6c\n",
        "!mkdir output1\n",
        "!mkdir output2\n",
        "!mkdir output3\n",
        "!mkdir output4"
      ],
      "metadata": {
        "id": "JrbxlVSv8Xnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 1"
      ],
      "metadata": {
        "id": "2HSl6zps6Dsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with detection on a live-action video: [Dr. Horrible's Sing Along Blog - Act 1](https://www.youtube.com/watch?v=jL_vEw6hObw).\n",
        "\n",
        "We'll take a frame every 2 seconds, enlarge the boxes from faces to ~portraits and square them.\n",
        "\n",
        "Every detection with a score <= 0.2 or width/height <= 20px will be rejected.\n",
        "\n",
        "Every face with an average hash difference <= 10 to some other face will be marked as a duplicate.\n",
        "\n",
        "We'll also save all intermediate results and logs for closer examination."
      ],
      "metadata": {
        "id": "HUsGPHY9q7jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m videotofaces -i 'videos/DrHorribleAct1.mp4' -o 'output1' -s 'live' -m 'detection' \\\n",
        "  --video-step 2 --det-scale 1.2 1.2 1.7 1.3 --det-square --det-min-score 0.2 --det-min-size 20 \\\n",
        "  --save-frames --save-rejects --save-dupes --hash-thr 10"
      ],
      "metadata": {
        "id": "jMfMePMprWua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once done, you can browse the results using a helper function (change page_number to see the rest):"
      ],
      "metadata": {
        "id": "lPeHDGegttyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from videotofaces import image_gallery\n",
        "image_gallery('output1/faces', page_size=36, page_number=0, height=110)"
      ],
      "metadata": {
        "id": "BVX3zuKUuI7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the intermediate results, you can browse the frames (rejects will be drawn red, others green):"
      ],
      "metadata": {
        "id": "qiMolAnbwolV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_gallery('output1/intermediate/frames', page_size=12, page_number=23, height=200)"
      ],
      "metadata": {
        "id": "oS62CS0sw34A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or the rejection log using different filters (e.g. detections with a score >= 0.15 but <= 0.2):"
      ],
      "metadata": {
        "id": "c1ESzTkLzfKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from videotofaces import dataframe_with_images\n",
        "dataframe_with_images('output1/intermediate/log_rejects.csv', 'output1', filter=('score', 0.15, 0.2), height=50)"
      ],
      "metadata": {
        "id": "oCJ07lefwoHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or the duplicates log by browsing the pairs with hash diffs from 9 (marked as dups) to 11 (barely passed):"
      ],
      "metadata": {
        "id": "mPOUeRFo05Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_with_images('output1/intermediate/log_dupes1.csv', 'output1', sort_by='hash_diff', filter=('hash_diff', 9, 11), height=100)"
      ],
      "metadata": {
        "id": "tjd38K2h0-aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's continue with grouping the detected results using K-means clustering, autoselecting the best number of clusters from 2 to 6.\n",
        "\n",
        "The duplicate check will also do another pass, now with embedding distances (<=0.2) instead of hash diffs."
      ],
      "metadata": {
        "id": "UtxSu_Zr2p3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m videotofaces -o 'output1' -s 'live' -m 'grouping' --clusters '2-6' --group-log --save-dupes --enc-dup-thr 0.2"
      ],
      "metadata": {
        "id": "2A5HlfKC2PBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Browsing the grouped results in their subfolders (you can see that it indeed managed to split them into 3 characters and 1 \"other\" category):"
      ],
      "metadata": {
        "id": "i6xdeN3h29eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_gallery('output1/faces', page_size=36, page_number=0, height=110, subfolders=True, centered=True)"
      ],
      "metadata": {
        "id": "Wwb81Lfx5ChX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the clustering log (4 clusters were chosen because of the highest silhouette score):"
      ],
      "metadata": {
        "id": "0eFyNVQo7E1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('output1/faces/log_clustering.csv')"
      ],
      "metadata": {
        "id": "lsY4x1t-7moK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also looking at the \"border line\" of the duplicate check just like with hashes:"
      ],
      "metadata": {
        "id": "5pL0yBwU-wtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_with_images('output1/intermediate/log_dupes3.csv', 'output1', sort_by='distance', filter=('distance', 0.18, 0.22))"
      ],
      "metadata": {
        "id": "qHm4HveU8YOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 2"
      ],
      "metadata": {
        "id": "xirbjEdP-3Pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try an anime video: [a fan trailer to S1 of \"A Certain Scientific Railgun\"](https://www.youtube.com/watch?v=jL_vEw6hObw).\n",
        "\n",
        "We'll launch both detection and grouping in one go this time.\n",
        "\n",
        "But instead of automatic clustering, we'll classify the results into predefined groups.\n",
        "\n",
        "For this, we need a folder with reference images. Here's the one prepped and uploaded to GDrive\n",
        "for this demo:"
      ],
      "metadata": {
        "id": "ZxrYdDotk0Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1mQS5wDyZ4zeb4NI-mbQYHYWkVrOBXUXN\n",
        "!unzip vtf_demo_ref.zip"
      ],
      "metadata": {
        "id": "Dtoqp2g9CJn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can take a look at the \"ref\" folder contents either with the helper function below or just through the Colab's file browser to the left, confirming that it containts 4 subfolders named after the anime's 4 main characters, each with a face image inside."
      ],
      "metadata": {
        "id": "_g_8jr4ophMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from videotofaces import image_gallery\n",
        "image_gallery('ref', subfolders=True)"
      ],
      "metadata": {
        "id": "zNO3BEq38mrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's read 2 frames every second this time (i.e. step = 0.5 sec) and set a threshold for \"other\" (meaning none of the 4 main characters) as 0.75.\n",
        "\n",
        "Launching the processing:"
      ],
      "metadata": {
        "id": "VF3lIWHQxotA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m videotofaces -i 'videos/Railgun1FanTrailer.mp4' -o 'output2' -s 'anime' \\\n",
        "  --video-step 0.5 --enc-oth-thr 0.75 \\\n",
        "  --group-mode 'classification' --ref-dir 'ref' --group-log"
      ],
      "metadata": {
        "id": "YEuYM9qvxcaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the classified results, you can see that everything was sorted correctly, including 4 images in the \"other\" group:"
      ],
      "metadata": {
        "id": "yvCNA4l9zh6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_gallery('output2/faces', subfolders=True, centered=True)"
      ],
      "metadata": {
        "id": "AJeUhUSpy6Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the classification log, you can see that, for example, **000120_0.jpg** was classified as \"2.kuroko\" because it had the smallest distance to that reference image (0.4624).\n",
        "\n",
        "And scrolling down to **002136_0.jpg**, you can see that the shortest distance there is 0.7743, meaning that for a higher \"other\" threshold (e.g. --enc-oth-thr 0.8) this image would've been wrongly classified as \"4.saten\"."
      ],
      "metadata": {
        "id": "c728wdXV1elO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('output2/faces/log_classification.csv')"
      ],
      "metadata": {
        "id": "8NfaarUHzIix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 3"
      ],
      "metadata": {
        "id": "F7fyBg3229NM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do one more short anime video: [Lycoris Recoil Trailer](https://www.youtube.com/watch?v=F5DMjhg3A6c).\n",
        "\n",
        "Taking 4 frames per second from 0:10 to 1:15, since the rest is intro/outro without faces.\n",
        "\n",
        "Clustering into 2, 4 or 6 groups and saving all 3 options for perusal, without autoselecting the best."
      ],
      "metadata": {
        "id": "DV5qEcGK28zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m videotofaces -i 'videos/LycoRecoTrailer.mp4' -o 'output3' -s 'anime' \\\n",
        "  --video-step 0.25 --video-fragment 0.15 1.25 \\\n",
        "  --group-mode 'clustering' --clusters '2,4,6' --clusters-save-all"
      ],
      "metadata": {
        "id": "lmLIN4QK2-3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring the results for 4 groups (change \"G4\" to \"G2\" or \"G6\" to explore the results for 2 or 6 groups):"
      ],
      "metadata": {
        "id": "YZT9Yn2v5IsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_gallery('output3/faces/G4', subfolders=True, centered=True)"
      ],
      "metadata": {
        "id": "irjmqMkE5GmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 4"
      ],
      "metadata": {
        "id": "KdtA-rIA5qKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's run the very same command as in Example 1 but using GPU video decoding with Decord library instead of the default OpenCV.\n",
        "\n",
        "For this, we'll need to build from source as per [Decord Readme instructions](https://github.com/dmlc/decord?tab=readme-ov-file#install-from-source):"
      ],
      "metadata": {
        "id": "O6AdvoOs5rvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo add-apt-repository ppa:jonathonf/ffmpeg-4\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y build-essential python3-dev python3-setuptools make cmake\n",
        "!sudo apt-get install -y ffmpeg libavcodec-dev libavfilter-dev libavformat-dev libavutil-dev\n",
        "\n",
        "# (see https://github.com/dmlc/decord/issues/102#issuecomment-710781378)\n",
        "# (run \"!find '/' -name libnvcuvid.so.1\" to ensure that the 1st path in your Colab runtime is the same)\n",
        "!ln -s /usr/lib64-nvidia/libnvcuvid.so.1 /usr/local/cuda/libnvcuvid.so\n",
        "\n",
        "!git clone --recursive https://github.com/dmlc/decord\n",
        "%cd decord\n",
        "!mkdir build\n",
        "%cd build\n",
        "\n",
        "!cmake .. -DUSE_CUDA=ON -DCMAKE_BUILD_TYPE=Release\n",
        "!make\n",
        "\n",
        "%cd ../python\n",
        "!python3 setup.py install --user\n",
        "\n",
        "%cd /content\n",
        "import decord"
      ],
      "metadata": {
        "id": "mjqlNMWy657W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Launching the detection process:"
      ],
      "metadata": {
        "id": "XeupXCqt_yTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m videotofaces -i 'videos/DrHorribleAct1.mp4' -o 'output4' -s 'live' -m 'detection' \\\n",
        "  --video-step 2 --det-scale 1.2 1.2 1.7 1.3 --det-square --det-min-score 0.2 --det-min-size 20 \\\n",
        "  --save-frames --save-rejects --save-dupes --hash-thr 10 \\\n",
        "  --video-reader 'decord'"
      ],
      "metadata": {
        "id": "-q7WFC695rJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see a noticeable speedup compared to the Example 1 (~45 sec vs >2 min).\n",
        "\n",
        "The difference could be much larger for long 1080p videos (where CPU video reading becomes a bottleneck), so for high-load processing on good GPUs this option is recommended.\n",
        "\n",
        "Feel free to browse the results as usual (and note that they might differ insignificantly from Example 1 because of Decord and OpenCV getting frames at slightly different points):"
      ],
      "metadata": {
        "id": "eqEnfOCQ_2tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from videotofaces import image_gallery\n",
        "image_gallery('output4/faces', page_size=36, page_number=0, height=110)"
      ],
      "metadata": {
        "id": "X1Ulk5d0_hf5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}